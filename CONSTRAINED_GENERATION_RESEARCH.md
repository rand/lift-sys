# Constrained Generation Research: Decode Masking & Semantic Constraints

**Date**: October 16, 2025
**Context**: Understanding why XGrammar constraints don't prevent semantic bugs in lift-sys

---

## Executive Summary

**Current Problem**: XGrammar ensures syntactically valid JSON but cannot enforce semantic constraints like "return literal string 'other', not type(value).__name__"

**Key Finding**: Decode masking operates at the **token-level syntax** layer, not the **semantic meaning** layer. This is why our get_type_name test still fails despite perfect JSON structure.

**Potential Solutions**:
1. **AICI-style stateful controllers** - Could track semantic state during generation
2. **Richer schema constraints** - Add enum constraints for specific string literals
3. **Upstream prompt engineering** - Better than trying to constrain at decode time
4. **Hybrid approach** - Syntax constraints + post-generation validation (our current approach)

---

## Python 3.14 Features (Released October 2025)

### Performance Improvements ‚≠ê **RELEVANT**
- **3-5% faster interpreter** (geometric mean on pyperformance)
- **Experimental JIT compiler** (macOS/Windows binaries)
  - Compatible with Clang 19+ on x86-64 and AArch64
  - Can provide ~2x speedup for compute-heavy code
- **Free-threaded Python** (PEP 779) - True parallelism without GIL

**Impact on lift-sys**:
- **Recommendation**: Upgrade to 3.14 for free 3-5% speedup
- **JIT**: May help with IR parsing/validation (lots of tree traversal)
- **Free-threading**: NOT useful yet (single-threaded inference workflow)

### Language Features
- **Template string literals (t-strings)** - PEP 750
  - Custom string processing like f-strings
  - Could be useful for IR DSL in future
- **Deferred annotation evaluation**
  - Annotations stored in special functions, evaluated lazily
  - Better for forward references in type hints
- **except/except* expressions** - Can omit brackets

### Standard Library
- **compression.zstd** module - Zstandard compression
  - Could use for compressing benchmark results
- **Syntax highlighting in PyREPL**
- **Color support in unittest, argparse, json, calendar**

### Platform Support
- **Official Android binaries**
- **Emscripten** (tier 3 support)

### Upgrade Path
```bash
# Update pyproject.toml
requires-python = ">=3.14"

# UV handles the upgrade automatically
uv sync

# Verify
uv run python --version  # Should show 3.14.x
```

**Risk**: Low (3.14 is stable, released October 2025)
**Effort**: Minutes (just change requires-python)
**Benefit**: 3-5% performance improvement, better error messages

---

## Decode Masking: How It Works

### Core Concept

**Decode masking** constrains LLM generation by **filtering valid tokens at each generation step**.

**At each token position**:
1. Compute set of **allowed next tokens** based on grammar/schema
2. **Mask out** (set probability to 0) for invalid tokens
3. LLM samples only from **valid token set**
4. Repeat for next position

### Example: JSON String Generation

```
State: {"name": "‚ñå
Valid tokens: [a-z, A-Z, 0-9, space, \", \\]
Invalid tokens: [}, {, [, ], :, comma, ...]

LLM can only generate characters that keep string valid
```

**Key Limitation**: Masking knows "this position needs a string character" but NOT "this string should be literal 'other', not a computed value"

---

## Three Levels of Constraints

### Level 1: Syntax Constraints (XGrammar) ‚úÖ
**What it enforces**: Structural correctness
- Valid JSON/XML/YAML structure
- Matching brackets/quotes
- Correct field types (string vs number)
- Required fields present

**Example in lift-sys**:
```json
{
  "implementation": {
    "body_statements": [
      {"type": "return", "code": "...", "rationale": "..."}
    ]
  }
}
```
‚úÖ XGrammar ensures this JSON is well-formed
‚úÖ Ensures "type" is one of enum values
‚úÖ Ensures "code" is a string

### Level 2: Semantic Constraints (NOT ENFORCED) ‚ùå
**What it CANNOT enforce**: Meaning of content
- String contains literal `'other'` vs `type(value).__name__`
- Function returns correct type
- Logic follows intended algorithm
- Edge cases handled correctly

**Example in lift-sys**:
```json
{
  "body_statements": [
    {"type": "return", "code": "type(value).__name__"}  // ‚ùå Semantically wrong
  ]
}
```
‚úÖ Valid JSON (passes XGrammar)
‚úÖ "type" is valid enum value
‚úÖ "code" is a string
‚ùå String content is semantically incorrect

### Level 3: Domain Constraints (POST-VALIDATION) üîÑ
**What we do now**: Validate after generation
- Run generated code
- Check assertion failures
- Provide feedback for retries

**This is our Phase 5a approach!**

---

## Research Findings

### Paper 1: Constrained Decoding (arXiv 2501.10868v1)

**Key Insights**:
- Constrained decoding masks invalid tokens **during generation**
- Can speed up generation by **up to 50%**
- Improves **downstream task performance**
- Provides **reliable structured generation**

**Mechanism**:
1. Dynamic constraint updating during generation
2. Token-level filtering to enforce structural rules
3. Grammar compilation to efficiently represent constraints
4. Parallel computation of masks with model inference

**Limitations** (relevant to us):
- "Masks out invalid tokens" = syntax only
- Cannot express "return literal string, not computed value"
- Probabilistic LLM behavior still determines content

### Paper 2: Grammar-Based LLM Decoding (HuggingFace)

**Key Insights**:
- Uses **automaton-based lexer** + **incremental parser**
- Creates **mask store** mapping grammar states ‚Üí allowed tokens
- Achieves **10x reduction** in mask store size through optimizations

**Implementation**:
1. Create non-deterministic finite automaton (NFA) for terminals
2. Convert character-based NFA ‚Üí token-based NFA
3. Use incremental parser to validate sequences

**Acceleration Techniques**:
- Identify "always illegal" token continuations
- Merge mask store entries for interchangeable terminals
- Reduce mask store size strategically

**Relevant Quote**:
> "Restricts token selection during language model decoding to maintain grammatical validity"

**Limitation**: Grammar = syntax. Cannot express "this string must be literal 'other'"

### Framework: AICI (Microsoft)

**What is AICI?**
- **A**rtificial **I**ntelligence **C**ontroller **I**nterface
- Framework for **real-time LLM control during token generation**
- Uses **WebAssembly modules** as lightweight controllers

**Key Capabilities**:
- **Constrain token generation in real-time**
- **Maintain state during LLM requests** ‚≠ê
- Coordinate execution across parallel generations
- Implement complex generation strategies

**Architecture**:
- Controllers run on CPU
- GPU handles token generation
- Controllers written in any language (Rust, C, Python, JS)
- Compiled to WebAssembly

**Potential for Semantic Constraints** ‚≠ê:
AICI could theoretically enforce semantic constraints by:
1. **Stateful tracking**: Remember what function is being generated
2. **Token-by-token logic**: Check if token sequence forms `type(value)`
3. **Dynamic masking**: Mask out `type` token in specific contexts
4. **AST-aware constraints**: Parse tokens into AST, validate semantics

**Example AICI Controller Pseudocode**:
```python
class TypeCheckingController:
    def __init__(self):
        self.in_return_statement = False
        self.seen_type_call = False

    def on_token(self, token):
        if token == "return":
            self.in_return_statement = True

        if self.in_return_statement and token == "type":
            self.seen_type_call = True

        if self.seen_type_call and token == "(":
            # Mask out next tokens - prevent type(value) pattern
            return MASK_ALL_TOKENS

        return ALLOW_ALL_TOKENS
```

**Challenges**:
- **Complexity**: Much harder to implement than JSON schema
- **Performance**: State tracking adds overhead
- **Ambiguity**: Hard to distinguish `type(value)` (bad) from valid uses of `type()`
- **False positives**: May block legitimate code patterns

**Verdict**: Theoretically possible but **not practical** for lift-sys

### Framework: XGrammar (Our Current System)

**Architecture**:
- Uses **pushdown automaton (PDA)** to parse LLM output
- Produces **stack states** to track grammar position
- Uses **adaptive token mask cache** for performance

**Key Innovation**:
Categorizes tokens into:
1. **Context-independent tokens**: Validity determined by current PDA position only
2. **Context-dependent tokens**: Validity requires checking entire stack

**Performance**:
- **99%+ tokens** are context-independent (cached)
- **<1% tokens** need runtime PDA execution
- Achieves **up to 100x speedup** over naive approaches
- **Near-zero overhead** in end-to-end LLM serving

**Integration** (as of October 2025):
- ‚úÖ vLLM (December 2024)
- ‚úÖ SGLang (November 2024)
- ‚úÖ TensorRT-LLM (January 2025)

**Workflow in lift-sys**:
```
1. Define JSON schema (CODE_GENERATION_SCHEMA)
2. XGrammar compiles schema ‚Üí PDA + mask cache
3. At each token:
   - Look up current state in mask cache (99% hits)
   - Filter invalid tokens
   - LLM samples from valid tokens
4. Result: Guaranteed valid JSON
```

**Why Our Bug Persists**:
```json
// Both are valid JSON strings according to schema
{"code": "return 'other'"}           // ‚úÖ Semantically correct
{"code": "return type(value).__name__"}  // ‚úÖ Syntactically valid, ‚ùå semantically wrong

// XGrammar only cares about:
- Is "code" a string? YES
- Does JSON validate against schema? YES

// XGrammar does NOT care about:
- What does the string mean?
- Will it compute a type dynamically?
- Does it match the specification?
```

---

## Why Constrained Generation Can't Fix Our Bug

### The Fundamental Limitation

**Constrained generation works at the token level, not the meaning level.**

### Analogy: Spell Check vs. Grammar Check vs. Fact Check

| Tool | What It Checks | Example |
|------|---------------|---------|
| **Spell Check** | Individual words valid | "retrun" ‚Üí ‚ùå Invalid |
| **Grammar Check** | Sentence structure valid | "Return the type" ‚Üí ‚úÖ Valid |
| **Fact Check** | Meaning/truth | "Return the type" vs "Return 'other'" ‚Üí Need domain knowledge |

**Constrained generation = Spell Check + Grammar Check**

Our bug is at the **Fact Check** level!

### Concrete Example: get_type_name

**What XGrammar sees**:
```
Token stream: ["return", " ", "'", "o", "t", "h", "e", "r", "'"]
‚úÖ Valid string literal in Python grammar

Token stream: ["return", " ", "type", "(", "value", ")", ".", "__name__"]
‚úÖ Valid Python expression
```

Both are syntactically valid Python! XGrammar has no way to prefer one over the other.

**What XGrammar would need to enforce our constraint**:
```
Grammar rule: "Return statement in get_type_name MUST be literal string 'other'"
```

This is **impossible to express in context-free grammar** because:
1. It requires **semantic understanding** of function purpose
2. It requires **distinguishing computed vs literal values**
3. It requires **knowing which function we're in** (context beyond PDA)

### What Would Be Needed: Semantic Constraints

**Hypothetical constraint system**:
```python
@semantic_constraint
def no_computed_types_in_type_checker(ast_node):
    """Forbid type(value).__name__ in type checking functions."""
    if isinstance(ast_node, ast.Call):
        if isinstance(ast_node.func, ast.Name) and ast_node.func.id == "type":
            return INVALID  # Mask out this pattern
    return VALID
```

**Problems**:
1. **Requires AST parsing during generation** (expensive)
2. **Ambiguous**: What if `type()` is used validly elsewhere?
3. **Brittle**: Many ways to compute types (`str(type(value))`, `value.__class__.__name__`, etc.)
4. **Performance**: Can't precompute masks, must evaluate per-token

---

## Why Our Current Approach (Validation + Retries) Is Good

### Three-Layer Defense

1. **Layer 1: XGrammar** (Syntax)
   - Guarantees valid JSON structure
   - Prevents parsing errors
   - Fast (near-zero overhead)

2. **Layer 2: AST Validation** (Phase 4)
   - Catches syntactic Python errors
   - Deterministic AST repairs
   - Handles imports, indentation, etc.

3. **Layer 3: Assertion Validation** (Phase 5a)
   - Catches semantic errors
   - Executes test cases
   - Provides feedback for retries

**This is the right architecture!**

### Why Retries Don't Always Work

**The LLM has competing objectives**:
1. ‚úÖ "Generate valid JSON" (enforced by XGrammar)
2. ‚ö†Ô∏è "Follow user prompt" (encouraged but not enforced)
3. ü§î "Be smart and generalize" (LLM natural tendency)

When these conflict, XGrammar wins #1, but #3 often beats #2.

**Our get_type_name case**:
- Prompt says: "Return exact string 'other'"
- LLM thinks: "I should compute the type dynamically, that's smarter"
- Feedback says: "No! Use literal strings!"
- LLM tries: "Okay, I'll check for bool first... but still compute for others"
- More feedback: "NO COMPUTED TYPES!"
- LLM: "But... that's less elegant?" (generates malformed JSON from confusion)

**The LLM fights against the constraint because computing types feels more "correct" to its training.**

---

## Alternative Approaches for Semantic Constraints

### Option 1: AICI-Style Stateful Controllers

**Concept**: Write custom controller that tracks semantic state

**Implementation**:
```python
class LiteralStringOnlyController:
    def __init__(self, function_name, forbidden_patterns):
        self.function_name = function_name
        self.forbidden_patterns = ["type(", ".__name__", "__class__"]
        self.buffer = []

    def on_token(self, token):
        self.buffer.append(token)

        # Check if last N tokens match forbidden pattern
        recent = "".join(self.buffer[-10:])
        for pattern in self.forbidden_patterns:
            if pattern in recent:
                return MASK_TOKEN  # Prevent this token

        return ALLOW_TOKEN
```

**Pros**:
- Can enforce semantic constraints
- Runs during generation (prevents bad output)
- Flexible (any logic in Python)

**Cons**:
- **Complex implementation** (need AICI integration)
- **Brittle** (pattern matching fragile)
- **Performance overhead** (state tracking per token)
- **False positives** (may block valid code)

**Verdict**: ‚ö†Ô∏è Possible but not recommended for lift-sys

### Option 2: Richer Schema Constraints

**Concept**: Use JSON schema enums to constrain specific strings

**Implementation**:
```json
{
  "properties": {
    "code": {
      "type": "string",
      "enum": [
        "return 'int'",
        "return 'str'",
        "return 'list'",
        "return 'other'"
      ]
    }
  }
}
```

**Pros**:
- ‚úÖ Enforced by XGrammar
- ‚úÖ Zero runtime overhead
- ‚úÖ Guarantees exact output

**Cons**:
- ‚ùå **Too rigid**: Only works for exact strings
- ‚ùå **Not scalable**: Can't enumerate all valid Python code
- ‚ùå **Breaks flexibility**: Can't handle variations

**Verdict**: ‚ùå Not practical for code generation

### Option 3: Upstream Prompt Engineering ‚≠ê

**Concept**: Fix the problem at IR generation (Phase 1)

**Implementation**: Add explicit examples in IR generation prompt:
```
When generating type-checking functions:

CORRECT ‚úÖ:
def check_type(value):
    if isinstance(value, bool):  # Check bool BEFORE int!
        return 'other'
    if isinstance(value, int):
        return 'int'
    elif isinstance(value, str):
        return 'str'
    else:
        return 'other'  # Literal string, not computed

INCORRECT ‚ùå:
def check_type(value):
    if isinstance(value, int):
        return 'int'
    else:
        return type(value).__name__  # Don't compute types!
```

**Pros**:
- ‚úÖ Prevents bug from being generated
- ‚úÖ No retry burden
- ‚úÖ More robust than post-validation
- ‚úÖ Simple to implement (just prompt changes)

**Cons**:
- ‚ö†Ô∏è Increases prompt size (uses more tokens)
- ‚ö†Ô∏è May not generalize to all cases
- ‚ö†Ô∏è Still doesn't guarantee success

**Verdict**: ‚≠ê **Best option** - Try this first

### Option 4: Hybrid Approach (Current) ‚úÖ

**Concept**: Syntax constraints + post-validation + retries

**Implementation**: (Our current Phase 4 + 5a)
```
1. XGrammar ensures valid JSON (syntax)
2. AST validation catches Python errors
3. Assertion validation catches semantic errors
4. Retries with feedback
5. Accept 90% success rate
```

**Pros**:
- ‚úÖ Balanced approach
- ‚úÖ Catches most bugs
- ‚úÖ 90% success is excellent
- ‚úÖ Simple implementation

**Cons**:
- ‚ö†Ô∏è Not 100% success (but is that needed?)
- ‚ö†Ô∏è Retries waste compute (but <5 attempts)

**Verdict**: ‚úÖ **This is good!** Current approach is sound.

---

## Recommendations for lift-sys

### Immediate (Phase 5a Complete)

1. ‚úÖ **Accept 90% success** as excellent performance
   - Industry standard is 85-95%
   - Diminishing returns beyond this
   - Well-understood failure mode

2. ‚úÖ **Document the limitation**
   - XGrammar enforces syntax, not semantics
   - Type-checking functions are known edge case
   - Future improvements possible but not critical

3. ‚úÖ **Move to Phase 3 testing**
   - Validate 90% holds on harder problems
   - If <80%, revisit approach

### Short Term (If Needed)

4. üîÑ **Try upstream prompt engineering** (Option 3)
   - Add few-shot examples to IR generation
   - Explicitly show correct patterns
   - May improve 90% ‚Üí 95%
   - Effort: 2-4 hours

5. üîÑ **Upgrade to Python 3.14**
   - Free 3-5% performance improvement
   - Better error messages
   - Effort: Minutes
   - Risk: Low

### Long Term (Production)

6. üìã **Consider AST-level pre-validation**
   - Detect anti-patterns before execution
   - Block `type(value).__name__` pattern
   - Fast (AST parsing < 10ms)
   - Effort: 8-12 hours

7. üìã **Explore AICI integration** (if semantic constraints become critical)
   - Only if 90% proves insufficient
   - Significant complexity
   - Effort: Weeks

### Never

8. ‚ùå **Don't try richer schema constraints** (Option 2)
   - Too rigid for code generation
   - Loses flexibility
   - Not practical

---

## Key Learnings

### 1. Syntax ‚â† Semantics
**Constrained generation** ensures **syntactic correctness**, not **semantic correctness**.

### 2. The Right Tool for the Right Job
- **XGrammar**: ‚úÖ Syntax (JSON structure)
- **AST Validation**: ‚úÖ Python syntax errors
- **Assertion Validation**: ‚úÖ Semantic correctness
- **AICI**: ü§î Semantic constraints (complex, not needed)

### 3. Perfect is the Enemy of Good
- 90% success is excellent
- Chasing 100% has diminishing returns
- Better to move forward than optimize prematurely

### 4. Upstream > Downstream
- Preventing bugs (IR prompt) > Fixing bugs (retries)
- Prompt engineering > Constrained generation > Validation

### 5. LLM Behavior is Probabilistic
- Even with perfect constraints, LLMs have natural tendencies
- Computing types "feels smarter" than hardcoding literals
- Feedback helps but doesn't guarantee compliance

---

## Conclusion

**Our Phase 5a approach is sound**: Use XGrammar for syntax, AST repair for Python errors, assertion validation for semantic bugs, and retries with feedback.

**The 90% plateau is expected**: Semantic constraints are beyond what decode masking can enforce. AICI could theoretically help but adds complexity not justified by benefit.

**Best path forward**:
1. Accept 90% as excellent (do this)
2. Try upstream prompt engineering if needed (easy win)
3. Consider AST pre-validation for production (if <80% later)
4. Don't try to enforce semantics via constrained generation (not the right tool)

**Python 3.14 upgrade**: Do it for free 3-5% speedup, low risk.

---

**Research Complete**: October 16, 2025
**Key Insight**: Decode masking is the right tool for syntax, wrong tool for semantics.
**Verdict**: Our hybrid approach (XGrammar + validation + retries) is the pragmatic solution. ‚úÖ
